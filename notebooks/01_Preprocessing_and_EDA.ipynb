{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b03afe5",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe651f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a3d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb423f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['clean_comment'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['clean_comment'].isna()]['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44821a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3355859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504dae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'clean_comment' column to lowercase\n",
    "df['clean_comment'] = df['clean_comment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['clean_comment'].apply(lambda x: x.endswith(' ') or x.startswith(' '))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing and leading whitespaces from the 'clean_comment' column\n",
    "df['clean_comment'] = df['clean_comment'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify comments containing URLs\n",
    "url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "comments_with_urls = df[df['clean_comment'].str.contains(url_pattern, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aafcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify comments containing new line characters\n",
    "comments_with_newline = df[df['clean_comment'].str.contains('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new line characters from the 'clean_comment' column\n",
    "df['clean_comment'] = df['clean_comment'].str.replace('\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d18b44",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10721488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of classes\n",
    "sns.countplot(data=df, x=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distribution of sentiments\n",
    "df['category'].value_counts(normalize=True).mul(100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column 'word_count'\n",
    "df['word_count'] = df['clean_comment'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['word_count'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figures and axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot KDE for category '1'\n",
    "sns.kdeplot(df[df['category'] == 1]['word_count'], label='Positive', fill=True)\n",
    "\n",
    "# Plot KDE for category '0'\n",
    "sns.kdeplot(df[df['category'] == 0]['word_count'], label='Neutral', fill=True)\n",
    "\n",
    "# Plot KDE for category '-1'\n",
    "sns.kdeplot(df[df['category'] == -1]['word_count'], label='Negative', fill=True)\n",
    "\n",
    "# Add title and label\n",
    "plt.title('Word Count Distribution by Category')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10c839",
   "metadata": {},
   "source": [
    "**Positive comments (category 1):** These tend to have a wider spread in word count, indicating that longer comments are more common in positive sentiments.  \n",
    "**Neutral comments (category 0):** The distribution shows a relatively lower frequency and is more concentrated around shorter comments compared to positive or negative ones.  \n",
    "**Negative comments (category -1):** These comments have a distribution somewhat similar to positive comments but with a smaller proportion of longer comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f693f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1eb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot for the 'wordcount' column categorized by 'category'\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(data=df, x='category', y='word_count')\n",
    "\n",
    "plt.title('Boxplot of Word Count by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77014772",
   "metadata": {},
   "source": [
    "**Positive comments (category 1):** The median word count is relatively high, and there are several outliers with longer comments, indicating that positive comments tend to be more verbose.  \n",
    "**Neutral comments (category 0):** The median word count is the lowest, with a tighter interquartile range (IQR), suggesting that neutral comments are generally shorter.  \n",
    "**Negative comments (category -1):** The word count distribution is similar to positive comments but with a slightly lower median and fewer extreme outliers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot between 'category' and 'wordcount'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='category', y='word_count', alpha=0.5)\n",
    "plt.title('Scatterplot of Word Count by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median word counts amoung sentiments\n",
    "sns.barplot(df, x='category', y='word_count', estimator='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download nltk stopwords if not already downloaded\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create a new column 'num_stop_words' by counting the number of stopwords in each comment\n",
    "df['num_stop_words'] = df['clean_comment'].apply(lambda x: len([word for word in x.split() if word in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distribution plot (displot) for the 'num_stop_words' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['num_stop_words'], kde=True)\n",
    "plt.title('Distribution of Stop Word Count in Comments')\n",
    "plt.xlabel('Number of Stop Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1489ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot KDE for category 1\n",
    "sns.kdeplot(df[df['category'] == 1]['num_stop_words'], label='Positive', fill=True)\n",
    "\n",
    "# Plot KDE for category 0\n",
    "sns.kdeplot(df[df['category'] == 0]['num_stop_words'], label='Neutral', fill=True)\n",
    "\n",
    "# Plot KDE for category -1\n",
    "sns.kdeplot(df[df['category'] == -1]['num_stop_words'], label='Negative', fill=True)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Num stop words Distribution by Category')\n",
    "plt.xlabel('Stop word count')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median word counts among sentiments\n",
    "sns.barplot(df,x='category',y='num_stop_words',estimator='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a frequency distribution of stop words in the 'clean_comment' column\n",
    "from collections import Counter\n",
    "\n",
    "# Extract all stop words from the comments using the previously defined 'common_stopwords'\n",
    "all_stop_words = [word for comment in df['clean_comment'] for word in comment.split() if word in stop_words]\n",
    "\n",
    "# Count the most common stop words\n",
    "most_common_stop_words = Counter(all_stop_words).most_common(25)\n",
    "\n",
    "# Convert the most common stop words to a DataFrame for plotting\n",
    "top_25_df = pd.DataFrame(most_common_stop_words, columns=['stop_word', 'count'])\n",
    "\n",
    "# Create the barplot for the top 25 most common stop words\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_25_df, x='count', y='stop_word', palette='viridis')\n",
    "plt.title('Top 25 Most Common Stop Words')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Stop Word')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_chars'] = df['clean_comment'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_chars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Combine all comments into one large string\n",
    "all_text = ' '.join(df['clean_comment'])\n",
    "\n",
    "# Count the frequency of each character\n",
    "char_frequency = Counter(all_text)\n",
    "\n",
    "# Convert the character frequency into a DataFrame for better display\n",
    "char_frequency_df = pd.DataFrame(char_frequency.items(), columns=['character', 'frequency']).sort_values(by='frequency', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff97254",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_frequency_df['character'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'num_punctuation_chars' to count punctuation characters in each comment\n",
    "df['num_punctuation_chars'] = df['clean_comment'].apply(\n",
    "    lambda x: sum([1 for char in x if char in '.,!?;:\"\\'()[]{}-'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_punctuation_chars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829556a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a function to extract the top 25 bigrams\n",
    "def get_top_ngrams(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "# Get the top 25 bigrams\n",
    "top_25_bigrams = get_top_ngrams(df['clean_comment'], 25)\n",
    "\n",
    "# Convert the bigrams into a DataFrame for plotting\n",
    "top_25_bigrams_df = pd.DataFrame(top_25_bigrams, columns=['bigram', 'count'])\n",
    "\n",
    "# Plot the countplot for the top 25 bigrams\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_25_bigrams_df, x='count', y='bigram', palette='magma')\n",
    "plt.title('Top 25 Most Common Bigrams')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Bigram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to extract the top 25 trigrams\n",
    "def get_top_trigrams(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "# Get the top 25 trigrams\n",
    "top_25_trigrams = get_top_trigrams(df['clean_comment'], 25)\n",
    "\n",
    "# Convert the trigrams into a DataFrame for plotting\n",
    "top_25_trigrams_df = pd.DataFrame(top_25_trigrams, columns=['trigram', 'count'])\n",
    "\n",
    "# Plot the countplot for the top 25 trigrams\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_25_trigrams_df, x='count', y='trigram', palette='coolwarm')\n",
    "plt.title('Top 25 Most Common Trigrams')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Trigram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-English characters from the 'clean_comment' column\n",
    "# Keeping only standard English letters, digits, and common punctuation\n",
    "import re\n",
    "\n",
    "df['clean_comment'] = df['clean_comment'].apply(lambda x: re.sub(r'[^A-Za-z0-9\\s!?.,]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccafe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ' '.join(df['clean_comment'])\n",
    "\n",
    "# Count the frequency of each character\n",
    "char_frequency = Counter(all_text)\n",
    "\n",
    "# Convert the character frequency into a DataFrame for better display\n",
    "char_frequency_df = pd.DataFrame(char_frequency.items(), columns=['character', 'frequency']).sort_values(by='frequency', ascending=False)\n",
    "\n",
    "char_frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Defining stop words but keeping essential ones for sentiment analysis\n",
    "stop_words = set(stopwords.words('english')) - {'not', 'but', 'however', 'no', 'yet'}\n",
    "\n",
    "# Remove stop words from 'clean_comment' column, retaining essential ones\n",
    "df['clean_comment'] = df['clean_comment'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb52d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply lemmatization to the 'clean_comment_no_stopwords' column\n",
    "df['clean_comment'] = df['clean_comment'].apply(\n",
    "    lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_cloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_word_cloud(df['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_cloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_word_cloud(df[df['category'] == 1]['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_cloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_word_cloud(df[df['category'] == 0]['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_cloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "plot_word_cloud(df[df['category'] == -1]['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_n_words(df, n=20):\n",
    "    \"\"\"Plot the top N most frequent words in the dataset.\"\"\"\n",
    "    # Flatten all words in the content column\n",
    "    words = ' '.join(df['clean_comment']).split()\n",
    "\n",
    "    # Get the top N most common words\n",
    "    counter = Counter(words)\n",
    "    most_common_words = counter.most_common(n)\n",
    "\n",
    "    # Split the words and their counts for plotting\n",
    "    words, counts = zip(*most_common_words)\n",
    "\n",
    "    # Plot the top N words\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(counts), y=list(words))\n",
    "    plt.title(f'Top {n} Most Frequent Words')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Words')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_top_n_words(df, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb12299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_n_words_by_category(df, n=20, start=0):\n",
    "    \"\"\"Plot the top N most frequent words in the dataset with stacked hue based on sentiment category.\"\"\"\n",
    "    # Flatten all words in the content column and count their occurrences by category\n",
    "    word_category_counts = {}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        words = row['clean_comment'].split()\n",
    "        category = row['category']  # Assuming 'category' column exists for -1, 0, 1 labels\n",
    "\n",
    "        for word in words:\n",
    "            if word not in word_category_counts:\n",
    "                word_category_counts[word] = { -1: 0, 0: 0, 1: 0 }  # Initialize counts for each sentiment category\n",
    "\n",
    "            # Increment the count for the corresponding sentiment category\n",
    "            word_category_counts[word][category] += 1\n",
    "\n",
    "    # Get total counts across all categories for each word\n",
    "    total_word_counts = {word: sum(counts.values()) for word, counts in word_category_counts.items()}\n",
    "\n",
    "    # Get the top N most frequent words across all categories\n",
    "    most_common_words = sorted(total_word_counts.items(), key=lambda x: x[1], reverse=True)[start:start+n]\n",
    "    top_words = [word for word, _ in most_common_words]\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    word_labels = top_words\n",
    "    negative_counts = [word_category_counts[word][-1] for word in top_words]\n",
    "    neutral_counts = [word_category_counts[word][0] for word in top_words]\n",
    "    positive_counts = [word_category_counts[word][1] for word in top_words]\n",
    "\n",
    "    # Plot the stacked bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bar_width = 0.75\n",
    "\n",
    "    # Plot negative, neutral, and positive counts in a stacked manner\n",
    "    plt.barh(word_labels, negative_counts, color='red', label='Negative (-1)', height=bar_width)\n",
    "    plt.barh(word_labels, neutral_counts, left=negative_counts, color='gray', label='Neutral (0)', height=bar_width)\n",
    "    plt.barh(word_labels, positive_counts, left=[i+j for i,j in zip(negative_counts, neutral_counts)], color='green', label='Positive (1)', height=bar_width)\n",
    "\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Words')\n",
    "    plt.title(f'Top {n} Most Frequent Words with Stacked Sentiment Categories')\n",
    "    plt.legend(title='Sentiment', loc='lower right')\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to show the highest frequency at the top\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_top_n_words_by_category(df, n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
